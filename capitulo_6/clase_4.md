![WideImg](https://fictizia.com/img/github/Fictizia-plan-estudios-github.jpg)

# [→ Máster en Big Data y Machine Learning](https://fictizia.com/formacion/master-big-data)
### Big Data, Machine Learning, Tensor Flow, Data Science, Data Analytics, Arquitecturas Big Data, Plataformas Big Data

## Capítulo 6 - Clase 4: Tratamiento y enriquecimiento de la información mediante Cloud DataFlow ##

### Introducción a Cloud DataFlow ###



**Recursos**

- [Introducción a Cloud DataFlow](https://airflow.apache.org/docs/stable/)
- [Guía de uso rápido de Cloud DataFlow para Python](
https://cloud.google.com/dataflow/docs/quickstarts/quickstart-python?hl=es-419)
- [Guía de uso rápido de Cloud DataFlow para Java](https://cloud.google.com/dataflow/docs/quickstarts/quickstart-java-maven?hl=es-419)
- [QuickLabs Cloud DataFlow](https://www.qwiklabs.com/focuses/1100?locale=es&parent=catalog)
- [Instalación de Cloud DataFlow mediante Pypi - Python](https://pypi.org/project/google-cloud-dataflow/)


### Introducción a Apache Beam ###

Cloud DataFlow es una tecnología basada en el proyecto [Apache Beam]() del ecosistema Apache. Apache Beam es un modelo de programación que permite desarrollar, de forma sencilla, procesos o aplicaciones para el tratamientos de datos en batch (lotes) y streaming. 

Apache Beam es un modelo de programación unificada que ofrece una forma fácil de implementar tareas de tratamiento de datos por lotes y en streaming y de ejecutarlas en cualquier motor de ejecución con una serie de IO distintas. ¿Suena prometedor, pero le sigue pareciendo confuso? Este el motivo por el que decidí publicar una serie de entradas de blog dedicadas a Apache Beam. En esta y en las siguientes entradas daré varios ejemplos concretos y destacaré determinados casos prácticos de tareas de tratamiento de datos mediante Apache Beam.

El tema de hoy es el procesamiento por lotes. Veamos el siguiente ejemplo: Usted trabaja en un concesionario de automóviles y desea analizar las ventas de vehículos a lo largo de un cierto periodo de tiempo (p. ej., cuántos coches de cada marca se vendieron). Esto significa que nuestro conjunto de datos es limitado (cantidad finita de datos) y no se actualizará (las ventas tuvieron lugar en el pasado). En este caso, podemos optar por un proceso por lotes para analizar nuestros datos.
