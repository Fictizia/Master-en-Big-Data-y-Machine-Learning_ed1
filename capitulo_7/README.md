![WideImg](https://fictizia.com/img/github/Fictizia-plan-estudios-github.jpg)

# [→ Máster en Big Data y Machine Learning](https://fictizia.com/formacion/master-big-data)
### Big Data, Machine Learning, Tensor Flow, Data Science, Data Analytics, Arquitecturas Big Data, Plataformas Big Data

## Capítulo 7 - Aprendizaje Automático ##

La capacidad de aprender es una de la funciones mentales más importantes de los seres vivos ya que les permite adaptarse a las necesidades del entorno con el objetivo de aumentar sus
posibilidades de supervivencia. Mediante el proceso de aprendizaje los seres vivos son capaces de modificar, adaptar y/o adquirir habilidades, destrezas, conocimientos y/o
comportamientos mediante la interacción con el entorno que les rodea. Este proceso puede ser incluso mucho más complejo desde la perspectiva de los seres humanos donde el proceso de
aprendizaje no se limita sólo al entorno y a sus interacciones con el, sino que también influyen ciertos factores sociales relacionados con valores y principios morales que influyen de manera
significativa sobre las diferentes habilidades, destrezas, conocimientos y conductas que somos capaces de aprender. Este tipo de diferencias (sesgo) se pueden apreciar significativamente
cuando comparamos dos individuos con las mismas capacidades cognitivas que han crecido en diferentes zonas geográficas del planeta donde existen significativas diferencias en la forma
de vida. Probablemente ambos individuos se comportarán de forma diferente ante estímulos similares ya que han creado modelos de comportamientos diferentes en base a la información
que han recibido.

Esta poderosa capacidad para construir modelos de comportamiento en base a la extracción y manipulación la información del entorno hicieron que los investigadores comenzaran a imitar el
proceso de aprendizaje humano con el fin de aumentar las capacidades de los diferentes algoritmos de Inteligencia Artificial los cuales estaban limitados por el conocimiento experto que
se les introducía para poder razonar y por los comportamientos (acciones, operaciones, etc) que eran definidos por los diseñadores de los sistemas. Es decir, los diferentes algoritmos de
Inteligencia Artificial no eran capaces de adaptarse a nuevas situaciones si están no habían sido previstas en los modelos que eran utilizados para producir el proceso de razonamiento.
Este nuevo área conocimiento perteneciente a la Inteligencia Artificial comenzó a denominarse __Aprendizaje Automático__ (Machine Learning, ML, en sus siglas en inglés) debido a que su
objetivo era construir modelos de comportamiento mediante el aprendizaje en base a la información disponible del entorno. Dependiendo de cómo se produce el proceso de
construcción de los modelos de aprendizaje podemos diferenciar entre diferentes modos de aprendizaje:

- Aprendizaje inductivo: Este tipo de modo de aprendizaje consiste en construir modelos a partir de un proceso de generalización mediante ejemplos simples. Es decir, permite identificar un conjunto de patrones comunes que permitan definir ciertas características
de los diferentes ejemplos utilizados en el proceso de aprendizaje. Este proceso se basa en el razonamiento inductivo[11] mediante el cual los humanos extraemos
conclusiones generales de forma independiente a través de un proceso de análisis de la información disponible con el fin de resolver un determinado problema. El conocimiento
utilizado siempre se considera nuevo y puede modificar o invalidar el modelo previamente aprendido.

- Aprendizaje analítico o deductivo: Este tipo de modo de aprendizaje consiste en construir modelos a partir de un proceso deductivo mediante la identificación de una
descripción general a partir de un conjunto de ejemplos los cuales son explicados de forma específica y completa. Este proceso se basa en el razonamiento deductivo mediante el cual los humanos aprendemos comunmente en el colegio donde se
presentan una serie de reglas o leyes las cuales son demostradas en base a una serie de ejemplos que explican de forma el funcionamiento de las diferentes leyes. El nuevo
conocimiento no invalida el conocimiento previo sólo lo completa o refuerza.
- Aprendizaje analógico: Este tipo de modo de aprendizaje consiste en construir modelos que permiten generar soluciones a problemas nuevos mediante la búsqueda de
similitudes con problemas previamente resueltos de forma que la solución de los problemas similares es adaptada a las particularidades del nuevo problema con el fin de
aprender una solución[13]. Este tipo de concepto de aprendizaje es el aplicado para diseñar los sistemas de razonamiento basados en caso descritos en el tema anterior. Algunos investigadores no lo consideran como un proceso total de aprendizaje ya que
depende de una fase de adaptación de puede producir muchisimas variaciones en la solución final.
- Aprendizaje conexionista: Este tipo de modo de aprendizaje consiste en construir modelos basados en las conexiones de entidades sencillas[] con el fin de aprender
ciertos conceptos en base a como se configuran estas conexiones. Este tipo de procesos de aprendizaje se han intentado aplicar en el proceso de construcción de
redes de neuronas con el fin de crear sistemas dinámicos que adaptan sus conexiones.
- Aprendizaje conductista: Este tipo de modo de aprendizaje, basado en la psicologia conductista, consiste en construir modelos en base a la observación y análisis de las
reacciones (conductas) aplicadas en el entorno como respuesta a un determinado estímulo que puede suponer una determinada recompensa.

La aparición del Aprendizaje Automático supuso un cambio radical en la forma en la que se estaba abordando el proceso de creación de sistemas basados en Inteligencia Artificial, ya que
a partir de este momento no se intentaban construir algoritmos que fuera capaces de resolver problemas de forma automática sino que se intentan construir algoritmos que fueran capaces
de aprender modelos en base a la información que tienen disponible. Esto supuso la aparición de diferentes tipos de familias de métodos que abordaban diferentes facetas del proceso de
aprendizaje comenzando con las primeras versiones del perceptrón[2][3] hasta los complejos modelos construidos mediante la utilización del Aprendizaje Profundo (Deep Learning) en base
a millones de datos y complejas estructuras basadas en redes de neuronas[4]. En los últimos años la aparición de diferentes frameworks[14][15], que facilitan el procesamiento y generación
de modelos de aprendizaje, ha supuesto que las empresas hayan centrado sus esfuerzos en utilizar este tipo de técnicas para ofrecer nuevos servicios y funcionalidades en un amplio grupo
de áreas como por ejemplo:

- Movilidad: Identificación de rutas por carretera más eficientes que minimicen el número de embotellamientos en las principales arterias de las ciudad disminuyendo el tiempo,
consumo y/o contaminación.
- Sistemas de producción: Predicción de errores de funcionamiento en sistema de producción supervisado o semisupervisado.
- Finanzas: Prevención de fraudes bancarías, lavado de dinero y personalizar la oferta de productos basados en datos del usuario y del mercado con el fin de conocer que tipo de
productos se adaptan mejor a un determinado usuario.
- Agricultura: Identificación de las mejores áreas de cultivo para cada tipo de producto, identificación de fechas de recogida de los productos en el momento óptimo de maduración, así como la identificación de los posible problemas en el proceso de crecimiento, identificación de enfermedades (visión artificial).
- Energía: Predicción de errores e identificación de zonas en la cual es necesario realizar algún tipo de mantenimiento preventivo. Identificación de los cambios en el coste de la
energía con el fin de recomendar a los clientes cuando aumentar o disminuir su consumo con el fin de minimizar los costes.
- Salud: Diagnostico y detección de enfermedades mediante el análisis de la información del usuario. Así como el uso de sistema de visión artificial para la detección de tumores.
- Farmacéutico: Optimizar de los diferentes estudios clínicos realizados mediante la selección automática de pacientes en base a sus características.

## FUNDAMENTOS BÁSICOS DEL APRENDIZAJE AUTOMÁTICO ##

Desde la perspectiva de una máquina el aprendizaje automático puede definirse como el proceso de adquisición de conocimiento de manera automática mediante la utilización de
ejemplos de entrenamiento que define las características del concepto que se desea aprender. Este proceso de adquisición de conocimiento (aprendizaje) puede ser visto como un proceso
de generación de cambios en el sistema que aprende (estudiante) los cuales son definidos por la información obtenida del entorno (ejemplos de entrada). Esta información puede ser definida
mediante otro sistema que nos enseña (profesor) que realiza una identificación de la información (datos etiquetados) o bien mediante la extracción de información en bruto que no
está identificada (datos no etiquetados). Estos implica que los sistemas de aprendizaje deben ser capaces de trabajar con un rango muy amplio de información de entrada, que pueden
incluir datos incompletos, inciertos, ruido, inconsistencias, etc con el fin de construir modelos imperfectos los cuales pueden ser analizados con el fin de conocer su grado de existo y
adecuación al problema. Dependiendo de cómo se utilice la información de entrada y salida durante el proceso de aprendizaje se pueden diferenciar entre cuatro grandes grupos o familias
de técnicas: aprendizaje supervisado, aprendizaje no supervisado, aprendizaje semisupervisado y el aprendizaje por refuerzo. 

<img src="./img/aprendizaje.png" alt="Elementos de un proceso de aprendizaje" width="800"/>

- Atributo: Los atributos, variables de entrada o componentes son las unidades básicas e indivisibles de información utilizada para representar algún tipo de conocimiento. Este tipo de información representa una característica básica que intenta describir algún tipo
de propiedad sobre los datos (color, tamaño, distancia, etc). Los atributos suelen clasificarse en dos categorías en base a los valores que pueden tomar:
- Continuos: Son aquellos atributos que toman un valor fijo dentro de un intervalo no finito perfectamente acotado donde dados dos valores observables siempre existe
un tercer valor intermedio que podría tomar el atributo continuo. Por ejemplo, la temperatura de una determinada habitación medida en grados centígrados puede
tomar valores de tipo real en un rango comprendido entre -50º y 50º centígrados.
- Discretos: Son aquellos atributos que toman su valor entre los elementos que forman un conjunto finito. Por ejemplo, los posible colores de pintura utilizados para pintar un vehículo.
- Instancia: Una instancia es la estructura de información básica utilizada para representar cada uno de los ejemplos que forma parte de los conjuntos de datos que
serán utilizados en el proceso de aprendizaje. Cada instancia, a su vez, está compuesta por un conjunto finito de atributos que la describen. Las instancia de un mismo conjunto
tienen que estar formadas por el mismo tipo de atributos. La Tabla 1 muestra un conjunto de instancia referentes a la climatología del entorno con el fin de saber si se
puede o no jugar un partido de tenis. Cada una de las instancias está compuesta por atributos de tipo continuo (Humedad) y discreto (Cielo, Temperatura y Viento).

ID Cielo Temperatura Humedad Viento Jugar (Etiqueta)
1 Soleado Alta 65,28 Leve Sí
2 Nublado Alta 60,45 Leve Sí
3 Lluvia Normal 68,12 Intensa No

- Objetivo (clase): Es un atributo especial utilizado para realizar la predicción, es decir es el objetivo de la predicción. Por ejemplo, la probabilidad de que un paciente tenga una
determinada enfermedad o el precio al que se venderá una vivienda.

-  Conjunto de datos: Es el conjunto de instancias que son utilizadas para el proceso de aprendizaje. La manera en la que este conjunto de información es utilizada depende del
tipo de técnica que estemos utilizando. Es decir, la información puede haber sido recogida previamente y almacenada en ficheros, u otro tipo de formato de
almacenamiento, que serán utilizados para construir en modelos o puede ser recogida en tiempo real durante el proceso de entrenamiento.

- Modelo: Es el resultado del proceso de aprendizaje. De manera formal se puede definir como el conjunto de reglas o patrones inferidos a partir del conjunto de entrenamiento
utilizado para construirlo.

- Algoritmo: Es el mecanismo mediante el cual se produce el proceso de aprendizaje. Este algoritmo funciona de manera diferentes dependiendo del tipo de salida y de
entrada que queremos utilizar para construir el modelo. Cada uno de los diferentes algoritmos de aprendizaje supervisado, no supervisado y semisupervisado puede
definirse como uno de los tres tipos de técnicas.

<img src="./img/tipos.png" alt="tipos de técnicas aprendizaje" width="800"/>

- Clasificación: Los algoritmos de clasificación son aquellos que tratan de predecir una salida de tipo discreto que consiste en un atributo de tipo discreto (clases) a partir de
un conjunto de datos que pueden estar o no etiquetados. Las diferentes instancias de entrada (entrenamiento y test) se encuentran
ordenadas en categorias o clases. Cada una de estas clases son las etiquetas que han sido asignadas a los datos. Se suelen diferenciar dos tipos de algoritmos:
clasificación binaria donde sólo es necesario predecir dos clases objetivo (Si o No) y clasificación multiclase donde se debe predecir más de 2 clases objetivo.

-  Regresión: Los algoritmos de regresión o estimación son aquellos que tratan de predecir una salida de tipo continuo que consiste en un valor numérico (número real)
a partir de un conjunto de datos etiquetados (Imagen central Figura 2 ). Cada una de las diferentes instancias de entrada (entrenamiento y test) tiene un atributo de
“salida” de tipo continuo.

- Agrupamiento: Los algoritmos de agrupamiento (clustering) son aquellos que tratan de predecir una salida de tipo discreto a partir de un conjunto de datos que pueden
estar o no etiquetados (Imagen derecha Figura 2 ). Es decir estos algoritmos son capaces de agrupar los elementos en base a las similitudes entre sus atributos en
un conjunto determinado de grupos, cuyo número debe ser incluido como una entrada más del algoritmo.

**El modelo de aprendizaje**

El proceso descrito en la sección anterior nos permite conocer cual son los componentes básicos para poder generar un modelo de aprendizaje pero no es tan sencillo. En primer lugar
este proceso difiere dependiendo de cada unas de las diferentes familias de métodos. Los algoritmos de aprendizaje no supervisado no suelen incluir una fase de test ya no la
información utilizada para el proceso de aprendizaje no está etiquetada y los algoritmos de aprendizaje por refuerzo modelan la información mediante la utilización de estados, acciones y
recompensas que de un punto de vista muy general pueden ser similares cambian por completo el proceso de aprendizaje. Los pares estado acción pueden ser visto como instancias
y el refuerzo como algo parecido a la clase. Todo esto será descrito de forma detallada en el siguiente tema de este curso.

Con respecto al proceso de aprendizaje en general es necesario introducir algunos conceptos básicos referentes al modelo y al tratamiento de la información utilizada para construirlo.

- Discretización: Es el proceso mediante el cual una variable de tipo continuo es transformada en una variable de tipo discreto. Este proceso normalmente se realiza
mediante la utilización de los valores disponibles en el conjunto de entrenamiento, en base a sus valores el conjunto es dividio en rangos donde cada uno se corresponderá
con un valor discreto de la nueva variable. Esta división se realiza comumente de manera manual lo cual hace que se introduzcan sesgos en el proceso de aprendizaje. Aunque existen técnicas que realizan divisiones automáticas del conjunto en rangos de
tamaño similar.

- Normalización: Es el proceso de ajuste de los diferentes valores de un atributo con el fin de disminuir importantes diferentes entre los valores o representarlos en otro tipo de
escala que permita analizar de forma más efectiva su efecto sobre el resto de los atributos o su significado. Lo más común es realizar una normalización a valores entre
0 y 1.

-  Valor atípico: Los valores atípicos o outliers son valores que pueden tomar los atributos muy distantes con respecto al resto de valores que poseen las otras instancias de los
conjuntos (entrenamiento y test) empleados en el proceso de aprendizaje. Estos cambios tan importantes en los valores de un atributo pueden significar que se ha
producido un error en medición o que se ha detectado un caso inusual que no es común que se reproduzca. Normalmente este tipo de valores son eliminados de los
conjuntos de entrenamiento y/o test debido a que pueden afectar de manera significativa al proceso de generación del modelo. Aunque este proceso de eliminación
puede ser bastante complicado si los conjuntos utilizados en el proceso de aprendizaje son muy grandes, por lo que algunas técnicas incluyen procesos para detección de
valores atípicos con el fin de eliminarlos y/o tratarlos de manera diferente durante el proceso de aprendizaje. Algunos de los métodos más utilizados para la detección de
estos valores son: (1) Métodos monovariables que búscan valores atípicos de forma individual en cada atributo con el fin de eliminarlos; (2) los Métodos multivariables que
buscan valores atípicos de instancias mediante la combinación de múltiples atributos; y (3) el Método de error de Minkowski que a diferencia de los otros dos no intentna
eliminar los valores atípicos sino minimizar su impacto en el modelo con el fin de no manipular el conjunto de entrenamiento como realizan los otros métodos. Un ejemplo
de valores atípicos serían los presentando en la Figura 3 , donde el valor de los atributos de los valores atipicos (rojo) difieren del valor que les debería corresponder
siguiente la trayectoria de la sigmoidal.

<img src="./img/atipicos.png" alt="Ejemplo de valores atípicos" width="800"/>

- Sobreajuste: El sobreajuste, sobreaprendizaje u overfitting es el efecto que se produce al sobreentrenar un modelo mediante un algoritmo de aprendizaje supervisado. Uno de
los problemas. El proceso de aprendizaje debe generar un modelo que permita predecir el resultado de otras instancias generalizando a partir de lo aprendido
mediante la utilización de la instancias de entrenamiento. Sin embargo, cuando el conjunto de entrenamiento se encuentra formado por instancias que no representan de
forma global el problema o está formado por casos muy minoritarios o poco comunes se puede producir un efecto de sobreentrenamiento. Este efecto hace que el modelo
generado por el algoritmo no sea capaz de generalizar y quede ajustado a unas características muy específicas de los datos de entrenamiento que no tiene relación
causal con la función objetivo.

- Ruido: El ruido es el conjunto de atributos o valores de un atributo específico que no aportan nada al proceso de aprendizaje y que pueden haber sido introducidos
mediante un proceso de medición incorrecto, un error en la inserción de los datos y simplemente son valores atípicos que puede afectar al proceso de aprendizaje debido
a su rareza. Es decir, es imposible utilizar este conjunto de valores y/o atributos con el fin de generar un modelo que sea capaz de generalizar en base a las instancias
utilizadas para construirlo. El ruido normalmente aporta muchísimas desventajas a la hora de construir un modelo, ya que tiende a aumentar la complejidad de los datos
complicando la ejecución de los algoritmos los cuales terminan generando modelos que no generalizan correctamente. Antes de construir un modelo es muy importante
analizar las instancias de entrenamiento con el fin de eliminar el posible ruido que existe. Este proceso puede ser muy complicado dependiendo del tamaño de los
conjunto de entrenamiento y test, por lo que existen diferentes aplicaciones que intentan eliminar el ruido de manera automática aunque no este tipo de herramiento no
suele asegurar la eliminación total del ruido o incluso pueden eliminar de manera erronea información que es relevante para el proceso de aprendizaje.
- Sesgo: El sesgo es probablemente uno de los conceptos más importante del Aprendizaje Automatico debido a su aparición puede producir que nuestro modelos
sean inservibles. El sesgo puede considerarse como un error del modelo generado el cual realiza predicciones “sesgadas” debido a que los datos utilizados para construirlo
están distorsionados de manera directa o indirecta. Un ejemplo típico de sesgo que ha aparecido en muchos de los primeros sistemas basados en visión artificial utilizados en
los vehículos autónomos donde el proceso de entrenamiento había sido sólo realizado con adultos de estatura media. Esto producía que el modelo no fuera capaz de
identificar a los niños como humanos. En el tema 9 de este curso se hará una descripción más detallada del concepto de sesgo y cual es su influencia en las
diferentes técnicas de Inteligia Artificial.

**Técnicas de Aprendizaje Automático**

Actualmente el Aprendizaje Automático está formado por un amplio número de técnicas, las cuales pueden ser clasificados en cuatro familias de técnicas en base a cómo se encuentra
modelada la información que usan para definir las entradas y la salida.

- Supervisado: Este tipo de técnicas son denominas como técnicas de aprendizaje mediante profesor debido a que la información que utilizan durante el proceso de
aprendizaje es completa. Es decir, las instancias de entrenamiento y test está formadas por atributos que definen las entradas las entradas y la salida esperada para cada
instancia (datos etiquetados). Su funcionamiento consiste en la identificación de una función (modelo) que sea capaz de realizar un mapeo entre las entradas y las salidas
conocida. Las técnicas de este grupo están basadas en clasificación y regresión.

- No supervisado: Este tipos de técnicas son más complejas que la anteriores debido a que la información que utilizan durante el proceso de aprendizaje es incompleta. Es
decir, las instancias de entrenamiento y test están formadas únicamente por atributos de entrada. No se conoce la salida esperada para ninguna de las instancias (datos no
etiquetados). Su funcionamiento consiste en la identificación de una función (modelo) que sea capaz de agrupar las diferentes instancias en base a ciertas características
comunes. Las técnicas de este grupo están basadas en clasificación y agrupamiento.

- Semisupervisado: En algunas ocasiones este tipo de técnicas son incluidos en uno de los grupos anteriores ya que la mayor parte de los algoritmos de este grupo puede
incluirse en alguno de los anteriores debido a que aplican algún tipo de transformación en los datos de entrada con el fin de poder aplicar alguno de los algoritmo de los grupos
anteriores o combinan algoritmos de ambos grupos. En mi opinión, debe ser clasificados en un grupo independiente debido a que utilizan información parcialmente
incompleta. Es decir, las instancias de entrenamiento o test no tienen una estructura totalmente similar debido a que algunas instancias están etiquetadas y otras no.

- Por refuerzo: Este es un tipo especial de técnicas de aprendizaje automático no supervisado debido a que utilizan una forma diferente de representación de la ejemplos
de entrenamiento basada en la utilización de estados y acciones, donde la aplicaciones de las acciones produce una realimentación en el entorno mediante recompensas. En el
 aprendizaje por refuerzo el objetivo consiste en construir un política para resolver un determinado problema. Esta política suele ser una secuencia de acciones que permiten
resolver le problema de manera óptima.

<img src="./img/tipos_aprendizaje.png" alt="Diferentes tipos de aprendizaje" width="800"/>

En la imagen se presentan diferentes tipos de algoritmos de Aprendizaje Automático distribuidos por familia (Supervisado, No supervisado y Por refuerzo) y por técnica (Regresión, Clasificación y Agrupamiento). En esta figura sólo se presentan algunos de las técnicas más utilizados, pero existen muchas más e incluso diferentes versiones de cada una de ellas.

## Aprendizaje Supervisado

El aprendizaje supervisado es una de las familias de métodos de aprendizaje basada en el aprendizaje inductivo[4] debido a que el proceso de aprendizaje se produce mediante instancias (ejemplos) etiquetadas. Este tipo de modelo de aprendizaje consiste en definir la información del entorno en pares de la forma (entrada – salida) de manera que ante nuevas entradas cuya salida es desconocida el sistema sea capaz de predecir la salida esperada en base a lo que ha aprendido durante el proceso de entrenamiento. La entrada se corresponde con las diferentes características que definen las instancias (ejemplos) y la salida se corresponde con el objetivo (clase o valor) al que pertenece en ejemplo. El proceso para identificar o definir esta función está dividido en dos fases:

- Fase de entrenamiento: Es la fase principal del proceso de aprendizaje y consiste en seleccionar aquellas características más relevantes de cada uno de los ejemplos de entrada comparándolas con otros ejemplos analizados previamente, mediante algún proceso de cotejamiento (identificación de patrones), de manera que cuando se detectan diferencias significativas se produce una adaptación del modelo que está siendo construido en base al aprendizaje. Este proceso puede ser visto como un sistema de identificación de patrones mediante la generalización de las características similares entre los diferentes ejemplos con el fin de construir un modelo que sea capaz de identificar los diferentes grupos de ejemplos con características similares. Es decir, el resultado del proceso de entrenamiento es un sistema formado por un conjunto de patrones que han sido identificados en base a las características de los ejemplos utilizados en el proceso de entrenamiento. 

- Fase de test: Esta es la fase secundaria y opcional del proceso de aprendizaje que nos permite validar el resultado de la fase entrenamiento mediante el uso de ejemplos que no han sido utilizados en la fase de entrenamiento con el fin de comprobar. Se suele considerar cómo una fase opcional debido a que no puede aplicarse a todos los tipos de algoritmos de Aprendizaje Automático. 

**Regresión Lineal**

La regresión lineal es un método matemático utilizado para estudiar la relación entre una conjunto de variables independientes (variables predictoras) y una variable dependiente (criterio o variable predecida)[18]. Dependiendo del número de variables independientes utilizadas en el proceso de predicción se pueden diferenciar entre regresión simple cuando sólo utilizamos una variable dependiente y regresión múltiple cuando utilizamos más de una variable independiente. Esta técnica permite desarrollar una ecuación lineal que puede ser utilizada para construir un modelo de predicción a partir de instancias con atributos discretos de entrada y salida.  

**Regresión lineal simple**

La regresión lineal simple consiste en calcular una ecuación lineal que relaciona una variable independiente x y una variable dependiente y. La ecuación lineal que debe ser calculada tiene la siguiente estructura:



donde y es la variable dependiente que queremos predecir en base a todas las demás,  y son parámetros desconocidos que deben ser calculado, x es la variable independiente y es el error cometido en la predicción. El proceso de aprendizaje consistiría en utilizar instancias de entrada (entrenamiento), compuestas cada una por dos valores uno para la variable independiente x y otro para la variable dependiente, para calcular los valores  y  que darían lugar a la ecuación de una recta donde  sería la ordenada en el origen, es decir es la altura a la que la recta corte el eje Y, y  es la pendiente de la recta, es decir es el incremento o decremento que se produce en la variable y cuando la variable x aumenta o disminuye una unidad. La siguiente imagen presenta el resultado de un proceso de regresión simple que consiste en aproximar una recta de regresión que se ajuste mejor la nube de puntos producidas por los valores utilizados para calcularla. 

<img src="./img/regresion.png" alt="Ejemplo de regresión lineal" width="800"/>

Una de los grandes problemas de esta técnica es que dado un conjunto de instancias de entrada (entrenamiento) existen infinitas rectas que pueden pasar por la nube de puntos por lo que es necesario elegir la recta que pasa lo más cerca posible de la mayor parte de los puntos. Por lo que el objetivo de aprendizaje consiste en encontrar la recta que represente mejor el conjunto de puntos. Existen diferentes técnicas matemáticas que permiten ajustar una función simple, siendo la más utilizada la técnica de mínimos cuadrados que permite identificar la recta que hace mínima la suma de los cuadrados de las distancias verticales entre cada punto y la recta. 

**Regresión lineal múltiple**

La regresión lineal simple es un caso particular de la regresión lineal múltiple que consiste en calcular una ecuación que relaciona un conjunto de variables independientes x1, x2, …, xn y una variable dependiente y. La ecuación para este caso de regresión tiene la siguiente estructura:


El funcionamiento de la regresión lineal múltiple es exactamente similar a la regresión lineal simple salvo con la diferencia de que tenemos múltiples variables independiente y de que la ecuación no representa una recta, sino que representará un plano cuando tengamos dos variables independientes, un espacio tridimensional cuando tenemos tres variables independientes y un hiperespacio cuando tengamos más de tres variables. 

**Redes de Neuronas**

Una Red de Neuronas Artificial (RNA) es una red representada de manera espacial mediante un grafo dirigido donde cada uno de los nodos representan neuronas y los arcos representan las sinapsis o conexiones entre las neuronas. Esta estructura intenta imitar la distribución de las neuronas en el cerebro humano con el fin de construir un tipo de algoritmo que sea capaz de simular la capacidad de procesamiento de nuestros cerebros. Para ello es necesario realizar una breve introducción de la estructura de una neurona humana con el fin de entender cuales sus similitudes. Las neuronas fueron descubiertas o identificadas por el científico español Ramón y Cajal en 1888, donde definió el cerebro como una red de aproximadamente 100 * 106 células individuales, denominadas neuronas, ampliamente interconectadas entre sí. Las neuronas humanas están formadas por tres elementos: (1) el soma o cuerpo celular es la parte principal de la neuronas (10 a 80 micras de longitud); (2) las múltiples prolongaciones que salen de distintas partes del soma, denominadas dendritas, cuya función consiste en recibir impulsos de otras neuronas y enviarlos hasta el soma; y (I3) el axón, que es una prolongación del soma que se extiende en dirección opuesta a las dendritas y tiene la función de conducir un impulso nervioso desde el soma hacia otra neurona, músculo o glándula del cuerpo humano. La Figura 8 presenta la estructura detallada de una neurona humana y sus diferentes partes. 

<img src="./img/neurona.png" alt="Ejemplo de regresión lineal" width="800"/>

En base a esta estructura biológica, los investigadores Pitts y McCulloch definieron el primer modelo de red neuronal en 1943. Este modelo consistía en una red con dos capas de neuronas conectadas entre sí, donde la primera capa estaba formada por conjunto de nodos o neuronas formales (neuronas presinápticas) que representaban la entrada de la red y la segunda capa estaba formada por  un único nodo o neurona formal (neurona postsináptica) que representaba la salida de la red. Una neurona formal era una puerta lógica con dos posibles estados internos (encendido o apagado) representados por una variable. Esta red funcionaba como un discriminador del estado de la puerta lógica, de forma que las neuronas de la primera capa recibían las entradas, que eran enviadas a la segunda capa donde se aplicaba una operación matemática obteniéndose un valor sobre el cual se aplicaba una función que activación, basada en un umbral, que definía el estado de la salida. Es decir, si el valor obtenido de la operación sobre las entradas era mayor que el umbral la salida era 1 y sino la salida era 0.  A partir de este y otros modelos que se desarrollaron en los siguiente años,  Rumelhart y McClelland introdujeron en 1986 lo que se conoce actualmente como el modelo estándar de neurona artificial, el cual se encuentra representado en la Figura , donde se presentan los componentes de una neurona artificial así como la correspondencia entre los elementos de una neurona biológica y una neurona artificial. Como se puede observar en la imagen la neurona artificial intenta imitar de forma completa la estructura de la neurona biológica. 

<img src="./img/estructura_nuerona.png" alt="Ejemplo de regresión lineal" width="800"/>

Un conjunto de entradas xj y un conjunto de pesos wij, denominados sinápticos, donde  j es un valor entre 1 y n. 
Una función de propagación hi definida a partir del conjunto de entradas y los pesos sinápticos. Es decir:

La función de propagación define la operación matemática mediante la cual se combinan las diferentes entradas que recibe la neurona. La función de propagación más comunmente utilizada consiste en combinar linealmente las entradas y los pesos sinápticos, mediante la siguiente operación matemática: 


Además es muy común añadir a la función de propagación un parámetro adicional θi, que comummente denomina umbral, el cual se suele restar al resultado de la operación

Una función de activación, que representa simultaneamente la salida de la neurona y su estado de activación. De forma matemática la función de activación se puede definir:

**Arquitectura de las redes de neuronas**

Una vez definidos los componentes básicos, es decir las neuronas, es necesario definir como se encuentran distribuidos y conectadas en la red. La distribución de las diferentes conexiones de la red determina en gran medida el funcionamiento de la red de neuronas. Los distintos nodos (neuronas) que componen la red se encuentran conectados entre sí mediante las sinapsis. Estas conexiones son unidireccionales, es decir, la información sólo se propaga en un único sentido desde la neurona presináptiva a la neurona possináptica. En general, las neuronas se agrupan entre si en base a la función de propagación que utilizan en entidades más grandes denominadas capas. La combinación secuencial de diferentes capas constituyen una red de neuronas artificial. En cualquier red de neuronas  artificial se pueden distinguir tres tipos de capas:

- Capa de entrada o sensorial: Es la capa inicial de la red de neuronas y está compuesta por neuronas que reciben información (datos o señales) del entorno.
- Capa de salida: Es la capa final de la red de neuronas y genera la salidad o respuesta de la red. 
- Capa oculta: Es la capa o capas intermedias de la red de neuronas donde se realizan las diferentes operaciones matemáticas que permiten a la red procesar y manipular la información con el fin de generar la salida de la red de neuronas. El caso más sencillo es que sólo exista una capa, pero pueden incluirse todas las capas que sean necesarias. La inclusión de múltiples capas ocultas ha dado lugar a las redes de neuronas profundas que se han popularizado en los últimos años mediante el Aprendizaje profundo (Deep Learning). Aunque este tipo de arquitecturas son muy eficientes para ciertos procesos aumenta en gran medida la complejidad de la red de neuronas. 

<img src="./img/red_neuronas.png" alt="Ejemplo de regresión lineal" width="800"/>

Dependiendo del número de capas ocultas que incluyamos en nuestra de red de neuronas artificial podemos hablar de redes monocapa que sólo están compuesta por una única capa oculta o redes multicapa donde existen múltiples capas ocultas. Además dependiendo de las conexiones entre las diferentes capas podemos distinguir entre tres tipos de redes de neuronas artificiales:

- Redes Unidireccionales (feedforward): La redes de neuronas unidireccionales o prealimientadas (debido a que las neuronas obtiene información de la capa anterior o del entorno) son las primera y más sencilla estructura de red neuronal artificial construida por el ser humano []. Es esta estructura de red, la información se mueve en una única dirección. Es decir, de la capa de entrada, a través de los diferentes capas ocultas (si existen) hacia los capas de salida. En este tipo de redes no existen ningún tipo de bucle o retroalimentación hacia atrás. Este tipo de redes, a pesar de su sencillez, ofrecen muy buenos resultados en procesos en los cuales no se requiera el uso de información de eventos futuros dentro de la red. 
-  Redes Elman (simple feeback): La redes de neuronas Elman son denominadas redes recurrentes simples ya que incluyen retroalimentación entre las capas contiguas. Es decir, en este tipo de red poseen una memoria de los eventos inmediatamente anteriores. Esta información es utilizada en el proceso de actualización de los pesos durante el proceso de apredizaje. 
-  Redes recurrentes (full feedback): La redes de neuronas recurrentes completamente conectadas, a diferencia de las redes de neuronas Elman, tienen conexiones de retroalimentación a todos los elementos que forman la red. Cada neurona de la red está conectada a todos los elementos que la rodean desde un punto de vista espacial.  Es decir, una neurona está conectada a las neuronas de las capas posterioes y anteriores y a si misma. 



Una vez que se ha definido la estructura de la red de neuronas es necesario computar el valor de los diferente pesos de cada una de las capas de la red, para ello se utiliza un proceso de entrenamiento compuesto por dos fases: 
- Fase de entrenamiento: En esta fase se calcula el valor de los pesos de la red, para ello se utiliza  un conjunto de datos o patrones (ejemplos de entrenamiento) que se utilizan para calcular los pesos (parámetros) que definen el modelo de la red de neuronas. Los diferentes pesos son calculados de manera iterativa, de acuerdo con los valores de los ejemplos entrenamiento, con el objeto de minimizar el error cometido entre la salida obtenida por la red neuronal y la salida deseada. 
- Fase de test: En esta se realiza un analisis de la calidad del proceso de entrenamiento, es decir se analiza si el modelo constrido en la fase anterior es capaz de generalizar a casos nuevos o se ha ajustado demasiado a las particularidades presentes en los ejemplos de entrenamiento (sobreajuste). Para evitar el problema del sobreajuste, es aconsejable utilizar un segundo grupo de datos diferentes a los de entrenamiento, el grupo de validación, que permita controlar el proceso de calculo de los pesos.

**Tipos de redes neuronas**

Las redes de neuronas se pueden construir de diferentes maneras dependiendo del número de capas, el tipo de neuronas utilizadas y la forma en la que están conectadas las diferentes capas. Pero existen una serie de configuraciones básicas que identifican cierto tipos de redes de neuronas, algunas de las cuales son descritas a continuación:

-Perceptrón simple: El perceptrón (Perceptron, P en sus siglas en inglés) es la red de neuronas más sencilla formada por sólo dos capas (entrada y salida) que permite construir un discriminador simple.   
- Perceptrón multicapa: El perceptrón multicapa (Multilayer Perceptron MP, en sus siglas en inglés)[] es una red de neuronas basada en el perceptrón simple que introduce el concepto de capa oculata. La estructura básica de esta red está formada por al menos tres capas (entrada, oculta y salida) cuya interacción permite construir un aproximador de tipo universal. Es decir, permite aproximar cualquier tipo de función continua definida en un espacio .
- Redes recurrentes: Las redes de neuronas recurrentes (Recurrent Neural Networks, RNN en sus siglas en inglés) son una extensión del perceptrón multicapa donde se producen conexiones entre las neuronas en ambos sentidos (hacia delante y hacia atrás). Existe dos tipos de redes recurrentes: simples que sólo tienen conexión con las neuronas de las capas continuas; y completas que pueden estar conectadas con todas las neuronas de las diferentes capas incluidas ellas mismas.  
- Redes largas de memoria a corto plazo: Las redes de neuronas largas con memoria a corto plazo (Long Short-Term Memory, LSTM en sus siglas en ingles) son un tipo de red de neuronas que incluye bloques de memoria que permite recordar cierto tipo de información. 
- Redes convolucionales: Las redes de neuronas convolucionales (Convolutional Neural Networks, CNN en sus siglas en inglés) son un tipo de red de neuronas similar al perceptrón multicapa donde las neuronas de algunas de sus capas son de tipo convolucional, de reducción del muestreo y sencillas. Las neuronas convolucionales tratan de simular el funcionamiento de las neuronas de la corteza visual humana mediante la aplicación de filtros (operaciones matriciales) que permiten la extracción de características de los datos de entradas que se corresponden con los píxeles de una imagen. 
- Redes generativas antagónicas: Las redes de neuronas generativas antagónicas (Generative Adversarial Network, GAN en sus siglas en inglés) son una combinación de dos redes de neuronas que compiten mutuamente en una juego de suma cero. El cual consiste una situación en la que la ganancia o pérdida de un participante se equilibra con exactitud con las pérdidas o ganancias del otro participante.
    
